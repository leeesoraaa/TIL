{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNeZYX923Tgxh3ohJ1HJtCl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 단어의 토큰화"],"metadata":{"id":"rRkxWjpY9_VA"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iidVbXyc4oiF","executionInfo":{"status":"ok","timestamp":1700536993148,"user_tz":-540,"elapsed":4189,"user":{"displayName":"이소라","userId":"11288745565484128360"}},"outputId":"5550a2b2-cad3-4174-a0af-02580c5edd17"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","원문:\n"," 해보지 않으면 해낼 수 없다.\n","\n","토큰화:\n"," ['해보지', '않으면', '해낼', '수', '없다']\n"]}],"source":["from tensorflow.keras.preprocessing.text import text_to_word_sequence\n","\n","text = '해보지 않으면 해낼 수 없다.'\n","\n","# 토큰화\n","result = text_to_word_sequence(text)\n","print('\\n원문:\\n', text)\n","print('\\n토큰화:\\n', result)"]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","\n","docs = ['먼저 텍스트의 각 단어를 나누어 토큰화합니다.',\n","        '텍스트의 단어로 토큰화해야 딥러닝에서 인식됩니다.',\n","        '토큰화한 결과는 딥러닝에서 사용할 수 있습니다.']\n","\n","# 토큰화 함수 지정\n","token = Tokenizer()\n","\n","# 토큰화 함수에 문장 적용\n","token.fit_on_texts(docs)\n","\n","# 단어의 빈도수를 계산한 결과 출력\n","print('\\n단어 카운트:\\n', token.word_counts)\n","\n","# 총 문장 개수\n","print('\\n문장 카운트:\\n', token.document_count)\n","\n","# 각 단어가 포함된 문장 수\n","print('\\n각 단어가 포함된 문장 카운트:\\n', token.word_docs)\n","\n","# 각 단어의 인덱스\n","print('\\n각 단어의 인덱스 값:\\n', token.word_index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nxr011Ra5xs5","executionInfo":{"status":"ok","timestamp":1700538074618,"user_tz":-540,"elapsed":395,"user":{"displayName":"이소라","userId":"11288745565484128360"}},"outputId":"ff5673ba-522c-420a-c436-09cd6299cc97"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","단어 카운트:\n"," OrderedDict([('먼저', 1), ('텍스트의', 2), ('각', 1), ('단어를', 1), ('나누어', 1), ('토큰화합니다', 1), ('단어로', 1), ('토큰화해야', 1), ('딥러닝에서', 2), ('인식됩니다', 1), ('토큰화한', 1), ('결과는', 1), ('사용할', 1), ('수', 1), ('있습니다', 1)])\n","\n","문장 카운트:\n"," 3\n","\n","각 단어가 포함된 문장 카운트:\n"," defaultdict(<class 'int'>, {'토큰화합니다': 1, '텍스트의': 2, '단어를': 1, '각': 1, '먼저': 1, '나누어': 1, '단어로': 1, '인식됩니다': 1, '토큰화해야': 1, '딥러닝에서': 2, '있습니다': 1, '토큰화한': 1, '결과는': 1, '사용할': 1, '수': 1})\n","\n","각 단어의 인덱스 값:\n"," {'텍스트의': 1, '딥러닝에서': 2, '먼저': 3, '각': 4, '단어를': 5, '나누어': 6, '토큰화합니다': 7, '단어로': 8, '토큰화해야': 9, '인식됩니다': 10, '토큰화한': 11, '결과는': 12, '사용할': 13, '수': 14, '있습니다': 15}\n"]}]},{"cell_type":"markdown","source":["# 단어의 원-핫 인코딩"],"metadata":{"id":"rkaOB_OP-CSN"}},{"cell_type":"code","source":["text = '오랫동안 꿈꾸는 이는 그 꿈을 닮아간다.'\n","\n","token = Tokenizer()"],"metadata":{"id":"hD2yIh836bnK"},"execution_count":null,"outputs":[]}]}